<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>在 iOS 设备上运行 TensorFlow 中训练好的模型 | GrayLand's blogs</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '23b02fe43688a2403eb3b2033320103d';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">在 iOS 设备上运行 TensorFlow 中训练好的模型</h1><a id="logo" href="/.">GrayLand's blogs</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">在 iOS 设备上运行 TensorFlow 中训练好的模型</h1><div class="post-meta">Sep 28, 2018</div><div class="post-content"><!-- 在 iOS 设备上运行 TensorFlow 中训练好的模型 -->
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>有2种方法可以在 iOS 设备上运行训练好的模型:</p>
<ol>
<li>导入 TensorFlow 的 iOS 版 <code>TensorFlow-experimental</code>, 然后在工程中使用 TensorFLow 的 C++ 版来实现.</li>
<li>将模型转换成 <code>CoreML</code> 所支持的格式 <code>*.mlmodel</code>, 然后使用<code>CoreML</code>框架实现.</li>
</ol>
<p>需要注意的是, 两个方法都需要使用 <code>.pb</code> 格式的模型.</p>
<p>来先说说<code>方法 1: 使用 TensorFlow-experimental</code></p>
<h2 id="方法1-使用-tensorflow-experimental-加载模型"><a class="markdownIt-Anchor" href="#方法1-使用-tensorflow-experimental-加载模型"></a> 方法1: 使用 TensorFlow-experimental 加载模型</h2>
<p>具体方法就不说了, 参见 <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/ios" target="_blank" rel="noopener">TensorFlow-example-iOS</a>. 运行项目前记得读 <code>README.md</code>, 主要就是说要先 <code>pod install/update</code> 一下, 然后再下载需要的模型文件到 <code>demo 项目的 data 目录下</code></p>
<p>这里有几个坑, 就是 <code>很多方法和 python 版的不同, 有的直接没有</code>.因为 <code>TensorFlow-experimental</code> 为了更好的适配移动端, 对 PC 版进行了一定阉割.</p>
<p>导致我在使用 <code>Inception-v3</code> 模型来测试的时候, 报了一个 <code>DecodeJpeg</code> 相关的错误</p>
<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Could not create TensorFlow Graph: Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs.  Registered devices: [CPU], Registered kernels:</span><br><span class="line">  &lt;no registered kernels&gt;</span><br><span class="line"></span><br><span class="line">	 [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=<span class="number">1</span>, channels=<span class="number">3</span>, dct_method=<span class="string">""</span>, fancy_upscaling=<span class="literal">true</span>, ratio=<span class="number">1</span>, try_recover_truncated=<span class="literal">false</span>](DecodeJpeg/contents)]]</span><br></pre></td></tr></table></figure>
<p>原因是内核没有注册<code>DecodeJpeg opertation</code>, 模型的计算图中有使用此方法, 故加载失败.</p>
<p>所以这里可以使用 <a href="https://github.com/tf-coreml/tf-coreml" target="_blank" rel="noopener">GitHub - tfcoreml</a> 对模型进行处理.</p>
<p>处理过程是这样的:</p>
<p>首先, 加载并打印<code>inception-v3</code>的计算图:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load the TF graph definition</span></span><br><span class="line">tf_model_path = <span class="string">'./tensorflow_inception_graph.pb'</span></span><br><span class="line"><span class="keyword">with</span> open(tf_model_path, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    serialized = f.read()</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">original_gdef = tf.GraphDef()</span><br><span class="line">original_gdef.ParseFromString(serialized)</span><br><span class="line"></span><br><span class="line"><span class="comment"># For demonstration purpose we show the first 15 ops the TF model</span></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> g:</span><br><span class="line">    tf.import_graph_def(original_gdef, name=<span class="string">''</span>)</span><br><span class="line">    ops = g.get_operations()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">15</span>):</span><br><span class="line">        print(<span class="string">'op id &#123;&#125; : op name: &#123;&#125;, op type: "&#123;&#125;"'</span>.format(str(i),ops[i].name, ops[i].type));</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">op id <span class="number">0</span> : op name: DecodeJpeg/contents, op type: <span class="string">"Const"</span></span><br><span class="line">op id <span class="number">1</span> : op name: DecodeJpeg, op type: <span class="string">"DecodeJpeg"</span></span><br><span class="line">op id <span class="number">2</span> : op name: Cast, op type: <span class="string">"Cast"</span></span><br><span class="line">op id <span class="number">3</span> : op name: ExpandDims/dim, op type: <span class="string">"Const"</span></span><br><span class="line">op id <span class="number">4</span> : op name: ExpandDims, op type: <span class="string">"ExpandDims"</span></span><br><span class="line">op id <span class="number">5</span> : op name: ResizeBilinear/size, op type: <span class="string">"Const"</span></span><br><span class="line">op id <span class="number">6</span> : op name: ResizeBilinear, op type: <span class="string">"ResizeBilinear"</span></span><br><span class="line">op id <span class="number">7</span> : op name: Sub/y, op type: <span class="string">"Const"</span></span><br><span class="line">op id <span class="number">8</span> : op name: Sub, op type: <span class="string">"Sub"</span></span><br><span class="line">op id <span class="number">9</span> : op name: Mul/y, op type: <span class="string">"Const"</span></span><br><span class="line">op id <span class="number">10</span> : op name: Mul, op type: <span class="string">"Mul"</span></span><br><span class="line">op id <span class="number">11</span> : op name: conv/conv2d_params, op type: <span class="string">"Const"</span></span><br><span class="line">op id <span class="number">12</span> : op name: conv/Conv2D, op type: <span class="string">"Conv2D"</span></span><br><span class="line">op id <span class="number">13</span> : op name: conv/batchnorm/beta, op type: <span class="string">"Const"</span></span><br><span class="line">op id <span class="number">14</span> : op name: conv/batchnorm/gamma, op type: <span class="string">"Const"</span></span><br></pre></td></tr></table></figure>
<p>看输出结果可以发现, 原始模型的输入是一个 <code>jpeg</code> 的<code>contents</code>, 开始对其进行了预处理. 这里作者直接把预处理去掉了, 把入口直接设置在了 <code>op id 9</code>这个位置, 即<code>Mul</code>操作</p>
<p>全部方法参见 Demo. 修改之后的模型, 入口参数变成了 <code>[1, 299, 299, 3]</code>的矩阵, 输出不变.</p>
<p>使用修改后的模型重试…</p>
<p>wht ??<br>
居然又出错了了, 错误信息:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Executor failed to create kernel. Invalid argument: NodeDef mentions attr 'dilations' not in Op&lt;name=Conv2D;</span><br></pre></td></tr></table></figure>
<p>原来是编译生成模型的版本和运行的版本不一致造成的, pod 上的版本是 <code>1.1.1</code>,<br>
PC上的是 <code>1.10.1</code>. 一些后来添加的新方法, 如 <code>dilations</code> op 在手机上就没有.</p>
<p>最后, 如果你的计算图用的操作都比较基础可以考虑使用<code>pod TensorFlow-experimental</code>方法部署, 否则请尝试<code>方法2</code> 或 根据 github 上的说明 <code>自行编译静态库</code>.</p>
<h2 id="方法2-转换模型并使用-coreml-部署"><a class="markdownIt-Anchor" href="#方法2-转换模型并使用-coreml-部署"></a> 方法2 转换模型并使用 CoreML 部署</h2>
<p>根据官方文档 <a href="https://developer.apple.com/documentation/coreml/converting_trained_models_to_core_ml?language=objc" target="_blank" rel="noopener">Converting Trained Models to Core ML | Apple Developer Documentation</a></p>
<p>可以使用工具来转换训练好的模型.</p>
<p>这里我使用 <a href="https://github.com/tf-coreml/tf-coreml" target="_blank" rel="noopener">GitHub - tf-coreml</a></p>
<p>具体使用方法<code>github文档</code> 写的很清楚了.</p>
<p>然后, 生成转换好的模型(figure-1)</p>
<p><img src="/2018/zisbsyxtfm/2e3e1d6e.jpg" alt="figure-1"></p>
<p>把转换好的 <code>inception_v3.mlmodel</code> 导入 <code>iOS项目</code>:</p>
<p><img src="/2018/zisbsyxtfm/35f3c3c5.jpg" alt="figure-2"></p>
<p>点击 <code>inception_v3.mlmodel</code> 可以查看到 model 的详情:</p>
<p><img src="/2018/zisbsyxtfm/41a5e1e3.jpg" alt="figure-3"></p>
<p>可以看到一些信息:</p>
<ul>
<li>Xcode 自动生成了一个与模型对应的类 <code>inception_v3</code></li>
<li>入口参数 <code>Mul__0</code>,输入<code>299x299</code>的 Image, 这个是转换的时候自己命名的</li>
<li>输出变量 <code>softmax__logits__0</code>, 也是转换的时候自己命名</li>
</ul>
<p>点击 <code>inception_v3</code> 右边的小箭头查看类文件, 可以看见其类型是 <code>CVPixelBuffer</code> 和 <code>prediction</code>方法.</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">var</span> <span class="type">Mul__0</span>: <span class="type">CVPixelBuffer</span></span><br><span class="line">...</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prediction</span><span class="params">(Mul__0: CVPixelBuffer)</span></span> <span class="keyword">throws</span> -&gt; inception_v3Output &#123;</span><br><span class="line">        <span class="keyword">let</span> input_ = inception_v3Input(<span class="type">Mul__0</span>: <span class="type">Mul__0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">try</span> <span class="keyword">self</span>.prediction(input: input_)</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>调用方法已经知道了, 现在需要把<code>Image</code> 转换成<code>CVPixelBuffer</code></p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">resizeImage</span><span class="params">(image: UIImage,with size: CGSize)</span></span> -&gt; <span class="type">UIImage</span> &#123;</span><br><span class="line">        <span class="type">UIGraphicsBeginImageContextWithOptions</span>(size, <span class="literal">false</span>, <span class="type">UIScreen</span>.main.scale)</span><br><span class="line">        image.draw(<span class="keyword">in</span>: <span class="type">CGRect</span>(x: <span class="number">0</span>, y: <span class="number">0</span>, width: size.width, height: size.height))</span><br><span class="line">        <span class="keyword">let</span> resizedImage: <span class="type">UIImage</span> = <span class="type">UIGraphicsGetImageFromCurrentImageContext</span>()!</span><br><span class="line">        <span class="type">UIGraphicsEndImageContext</span>()</span><br><span class="line">        <span class="keyword">return</span> resizedImage</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> inputImage = resizeImage(image: image!, with: <span class="type">CGSize</span>(width: <span class="number">299</span>, height: <span class="number">299</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> pixelBufferAttr = [kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,</span><br><span class="line">                               kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue] <span class="keyword">as</span> <span class="type">CFDictionary</span></span><br><span class="line">        </span><br><span class="line"><span class="keyword">var</span> pixelBuffer : <span class="type">CVPixelBuffer</span>?</span><br><span class="line"><span class="keyword">let</span> status = <span class="type">CVPixelBufferCreate</span>(kCFAllocatorDefault, <span class="number">299</span>, <span class="number">299</span>, kCVPixelFormatType_32ARGB, pixelBufferAttr, &amp;pixelBuffer)</span><br><span class="line"><span class="keyword">guard</span> (status == kCVReturnSuccess) <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"转换CVPixelBuffer失败!"</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">CVPixelBufferLockBaseAddress</span>(pixelBuffer!, <span class="type">CVPixelBufferLockFlags</span>(rawValue: <span class="number">0</span>))</span><br><span class="line"><span class="keyword">let</span> pixelData = <span class="type">CVPixelBufferGetBaseAddress</span>(pixelBuffer!)</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> rgbColorSpace = <span class="type">CGColorSpaceCreateDeviceRGB</span>()</span><br><span class="line"><span class="keyword">let</span> context = <span class="type">CGContext</span>(data: pixelData, width: <span class="type">Int</span>(inputImage.size.width), height: <span class="type">Int</span>(inputImage.size.height), bitsPerComponent: <span class="number">8</span>, bytesPerRow: <span class="type">CVPixelBufferGetBytesPerRow</span>(pixelBuffer!), space: rgbColorSpace, bitmapInfo: <span class="type">CGImageAlphaInfo</span>.noneSkipFirst.rawValue)</span><br><span class="line"></span><br><span class="line">context?.translateBy(x: <span class="number">0</span>, y: inputImage.size.height)</span><br><span class="line">context?.scaleBy(x: <span class="number">1.0</span>, y: -<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="type">UIGraphicsPushContext</span>(context!)</span><br><span class="line">inputImage.draw(<span class="keyword">in</span>: <span class="type">CGRect</span>(x: <span class="number">0</span>, y: <span class="number">0</span>, width: inputImage.size.width, height: inputImage.size.height))</span><br><span class="line"><span class="type">UIGraphicsPopContext</span>()</span><br><span class="line"><span class="type">CVPixelBufferUnlockBaseAddress</span>(pixelBuffer!, <span class="type">CVPixelBufferLockFlags</span>(rawValue: <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<h4 id="使用-coreml-进行预测"><a class="markdownIt-Anchor" href="#使用-coreml-进行预测"></a> 使用 CoreML 进行预测</h4>
<p>附上关键部分代码来体现处理逻辑:</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> image = loadImage()</span><br><span class="line"><span class="keyword">let</span> myModel = inception_v3()</span><br><span class="line"><span class="keyword">var</span> pixelBuffer = converToBuffer(image)</span><br><span class="line"><span class="keyword">let</span> result: inception_v3Output = <span class="keyword">try</span> myModel.prediction(<span class="type">Mul__0</span>: pixelBuffer!) <span class="keyword">as</span> inception_v3Output</span><br><span class="line"></span><br><span class="line"><span class="comment">// result 就是输出结果 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> <span class="built_in">min</span>: <span class="type">Float</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">var</span> index = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">0</span>..&lt;result.softmax__logits__0.<span class="built_in">count</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> result.softmax__logits__0[i].floatValue &gt; <span class="built_in">min</span> &#123;</span><br><span class="line">        <span class="built_in">min</span> = result.softmax__logits__0[i].floatValue</span><br><span class="line">        index = i</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"result.softmax__logits__0.count="</span>, result.softmax__logits__0.<span class="built_in">count</span>)</span><br><span class="line"><span class="comment">// index 即为所在标签的位置</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"index="</span>, index)</span><br></pre></td></tr></table></figure>
<p>运行效果:</p>
<p><img src="/2018/zisbsyxtfm/0ace23cb.jpg" alt="0ace23cb"></p>
<p>另外, 这里也可以使用<code>Vision</code>来进行处理, 这样可以免去转换<code>CVPixelBuffer</code>.</p>
<p>详情参见官网文档 <a href="https://developer.apple.com/documentation/vision/classifying_images_with_vision_and_core_ml?language=objc" target="_blank" rel="noopener">Classifying Images with Vision and Core ML | Apple Developer Documentation</a></p>
</div><iframe src="/donate/?AliPayQR=/img/glAlipay.JPG&amp;WeChatQR=/img/glWechatPay.JPG&amp;GitHub=null&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div class="tags"><a href="/tags/iOS-TensorFlow-CoreML-Vision/">iOS, TensorFlow, CoreML, Vision</a></div><div class="post-nav"><a class="next" href="/2018/hexosimg/">Hexo 配置图文方法</a></div><div id="container"></div><link rel="stylesheet" href="/css/default.css?v=0.0.0"><script src="/js/gitment.browser.js?v=0.0.0"></script><script>var gitment = new Gitment({
  owner: 'GrayLand119',
  repo: 'GrayLand119.github.io',
  oauth: {
    client_id: 'bb3e21016786a32e92ce',
    client_secret: 'fec0106c72a4aaaa8251129c27dd6d59ed34c3ed',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://grayland119.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Xcode/">Xcode</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/iOS/">iOS</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/OpenCV/" style="font-size: 15px;">OpenCV</a> <a href="/tags/Runtime/" style="font-size: 15px;">Runtime</a> <a href="/tags/iOS/" style="font-size: 15px;">iOS</a> <a href="/tags/Xcode/" style="font-size: 15px;">Xcode</a> <a href="/tags/lldb/" style="font-size: 15px;">lldb</a> <a href="/tags/ReactiveCocoa/" style="font-size: 15px;">ReactiveCocoa</a> <a href="/tags/Git/" style="font-size: 15px;">Git</a> <a href="/tags/Objc/" style="font-size: 15px;">Objc</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/iOS逆向/" style="font-size: 15px;">iOS逆向</a> <a href="/tags/iOS轮子/" style="font-size: 15px;">iOS轮子</a> <a href="/tags/TensorFlow/" style="font-size: 15px;">TensorFlow</a> <a href="/tags/iOS-TensorFlow-CoreML-Vision/" style="font-size: 15px;">iOS, TensorFlow, CoreML, Vision</a> <a href="/tags/Other/" style="font-size: 15px;">Other</a> <a href="/tags/iOS规范/" style="font-size: 15px;">iOS规范</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/zisbsyxtfm/">在 iOS 设备上运行 TensorFlow 中训练好的模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/hexosimg/">Hexo 配置图文方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/tfln10/">TensorFlow学习笔记(10) - 队列与多线程及输入数据框架</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/tfln9/">TensorFlow学习笔记(9) - 图像处理数据</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/tfln8/">TensorFlow学习笔记(8) - 迁移学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/tfln7/">TensorFlow学习笔记(7) - 经典CNN模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/tfln6/">TensorFlow学习笔记(6) - CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/tfln5/">TensorFlow学习笔记(5) - 完善手写体识别</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/tfln4/">TensorFlow学习笔记(4) - 持久化原理及数据格式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/tfln3/">TensorFlow学习笔记(3) - 模型持久化</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">GrayLand's blogs.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>